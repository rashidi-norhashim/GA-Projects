{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Capstone: Detecting Manufacturing Nonconformities through Live Video Deep Learning Classification<br>\n",
    "\n",
    "# Webcam Video Feed and Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T16:23:15.104333Z",
     "start_time": "2022-05-11T16:23:15.090330Z"
    }
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T16:33:11.369506Z",
     "start_time": "2022-05-11T16:33:00.588330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is operational.\n"
     ]
    }
   ],
   "source": [
    "cap = cv.VideoCapture(0) # 0 for webcam, filepath for a video file.\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera.\")\n",
    "else:\n",
    "    print(\"Camera is operational.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Webcam Streaming/Capture Specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T16:33:43.038569Z",
     "start_time": "2022-05-11T16:33:11.402515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0 1280.0 720.0\n"
     ]
    }
   ],
   "source": [
    "ret = cap.set(cv.CAP_PROP_FRAME_WIDTH,1280)\n",
    "ret = cap.set(cv.CAP_PROP_FRAME_HEIGHT,720)\n",
    "ret = cap.set(cv.CAP_PROP_FPS,5)\n",
    "\n",
    "fps = cap.get(cv.CAP_PROP_FPS)\n",
    "width  = cap.get(cv.CAP_PROP_FRAME_WIDTH)   # float\n",
    "height = cap.get(cv.CAP_PROP_FRAME_HEIGHT)  # float\n",
    "\n",
    "print(fps, width, height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Streaming/Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T16:24:49.190832Z",
     "start_time": "2022-05-11T16:24:36.441466Z"
    }
   },
   "outputs": [],
   "source": [
    "#setting video format\n",
    "fourcc = cv.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "out = cv.VideoWriter('../video/output.avi', fourcc, fps, (int(width), int(height)))\n",
    "\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        #out.write(frame) #outputs a video\n",
    "        cv.imshow('frame',frame)\n",
    "       \n",
    "        if cv.waitKey(1) & 0xFF == ord('q'): #press 'q' to exit\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "out.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T16:05:07.405806Z",
     "start_time": "2022-05-11T16:05:07.395803Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#release camera if job is done\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Capture from Video Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting video format\n",
    "fourcc = cv.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "out = cv.VideoWriter('../video/create.avi', fourcc, fps, (int(width), int(height)))\n",
    "i = 1\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret==True:\n",
    "\n",
    "        cv.imshow('frame',frame)        \n",
    "        cv.imwrite('../img/progressive/empty/step2'+str(i)+'.jpg', frame) #outputs an image\n",
    "        i += 1\n",
    "          \n",
    "        if (cv.waitKey(1) & 0xFF == ord('q')):\n",
    "            break\n",
    "    else:\n",
    "            break\n",
    "\n",
    "out.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T16:05:10.990655Z",
     "start_time": "2022-05-11T16:05:10.976652Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#release camera if job is done\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Video Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finished Assembly Model Live Video Classification (Base Dataset/Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T16:32:46.298305Z",
     "start_time": "2022-05-11T16:32:44.554201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 240, 320, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 120, 160, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 118, 158, 64)      9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 59, 79, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 298304)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                19091520  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 19,103,361\n",
      "Trainable params: 19,103,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('../model/cnn_model_finished_w_variation_all/')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T16:33:54.153620Z",
     "start_time": "2022-05-11T16:33:47.082767Z"
    }
   },
   "outputs": [],
   "source": [
    "#setting video format\n",
    "fourcc = cv.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "out = cv.VideoWriter('../video/output_finished_v.avi', fourcc, fps, (int(width), int(height)))\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "while True:\n",
    "        _, frame = cap.read()\n",
    "\n",
    "        #Convert the captured frame into RGB\n",
    "        imageRGB = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        \n",
    "        #image transformations\n",
    "        im = Image.fromarray(imageRGB)\n",
    "        im = im.resize((320,240))\n",
    "        img_array = np.array(im) / 255\n",
    "\n",
    "        #Expand dimensions to match the 4D Tensor shape for prediction\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        \n",
    "        #prediction\n",
    "        prediction = model.predict(img_array)\n",
    "\n",
    "        # Defining font, scales and thickness.\n",
    "        fontFace = cv.FONT_HERSHEY_DUPLEX \n",
    "        text_scale = 1.2\n",
    "        \n",
    "        #printing of prediction probability and class into the frame\n",
    "        if prediction > 0.5:\n",
    "            text = f'\"PASS\": {np.round(prediction[0][0]*100,2)}%'\n",
    "            frame = cv.putText(frame, text, org=(10,35), fontFace=fontFace, fontScale=text_scale, thickness=2, color=(0, 255, 0), lineType=cv.LINE_AA)\n",
    "        else:\n",
    "            text = f'\"FAIL\": {np.round(prediction[0][0]*100,2)}%'\n",
    "            frame = cv.putText(frame, text, org=(10,35), fontFace=fontFace, fontScale=text_scale, thickness=2, color=(0, 0, 255), lineType=cv.LINE_AA)\n",
    "\n",
    "        #video output\n",
    "        cv.imshow(\"Prediction\", frame)\n",
    "\n",
    "        #out.write(frame) #saving the video output\n",
    "        key=cv.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "                break\n",
    "\n",
    "out.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T16:34:05.544601Z",
     "start_time": "2022-05-11T16:34:04.963399Z"
    }
   },
   "outputs": [],
   "source": [
    "#release camera if job is done\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Finished Assembly Model Live Video Classification (ROI Dataset/Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T16:25:06.636255Z",
     "start_time": "2022-05-11T16:25:05.128305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 250, 200, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 125, 100, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 123, 98, 64)       9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 61, 49, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 191296)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                12243008  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 12,254,849\n",
      "Trainable params: 12,254,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('../model/cnn_model_finished_cropped/')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T16:25:26.857411Z",
     "start_time": "2022-05-11T16:25:10.763694Z"
    }
   },
   "outputs": [],
   "source": [
    "#setting video format\n",
    "fourcc = cv.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "out = cv.VideoWriter('../video/output_finished_v.avi', fourcc, fps, (int(width), int(height)))\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "while True:\n",
    "        _, frame = cap.read()\n",
    "\n",
    "        #Convert the captured frame into RGB\n",
    "        imageRGB = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        \n",
    "        #image transformations\n",
    "        im = Image.fromarray(imageRGB)\n",
    "        #im = im.resize((320,240)) #for non-ROI models\n",
    "        img_array = np.array(im) / 255\n",
    "\n",
    "        #for ROI models. setting pixels for cropping ROIs\n",
    "        cropped_1strow = np.concatenate((img_array[101:152, 385:435], img_array[101:152, 561:611], img_array[101:152, 655:705], img_array[101:152, 831:881]), axis = 1)\n",
    "        cropped_2ndrow = np.concatenate((img_array[258:323, 375:425], img_array[258:323, 555:605], img_array[258:323, 660:710], img_array[258:323, 838:888]), axis = 1)\n",
    "        cropped_3rdrow = np.concatenate((img_array[353:417, 370:420], img_array[353:417, 550:600], img_array[353:417, 664:714], img_array[353:417, 845:895]), axis = 1)\n",
    "        cropped_4throw = np.concatenate((img_array[549:619, 356:406], img_array[549:619, 550:600], img_array[549:619, 664:714], img_array[549:619, 856:906]), axis = 1)\n",
    "        cropped = np.concatenate((cropped_1strow, cropped_2ndrow, cropped_3rdrow, cropped_4throw), axis = 0)\n",
    "                \n",
    "        #video output of the cropped video\n",
    "        croppedBGR = cv.cvtColor(cropped.astype(np.float32), cv.COLOR_RGB2BGR)\n",
    "        cv.imshow(\"Cropped\", croppedBGR)\n",
    "\n",
    "        #Expand dimensions to match the 4D Tensor shape for prediction\n",
    "        cropped = np.expand_dims(cropped, axis=0) #img_array = np.expand_dims(img_array, axis=0) # for non-ROI models\n",
    "\n",
    "        #prediction\n",
    "        prediction = model.predict(cropped)\n",
    "\n",
    "        #Final Picture\n",
    "        #setting rectangles for ROI models\n",
    "        #1st Row\n",
    "        frame = cv.rectangle(frame, (385, 101), (434, 152), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (561, 101), (615, 152), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (650, 101), (705, 152), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (833, 101), (881, 152), (0, 255, 255), thickness=2)\n",
    "        #2nd Row\n",
    "        frame = cv.rectangle(frame, (367, 258), (426, 323), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (554, 258), (610, 323), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (649, 258), (709, 323), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (840, 258), (898, 323), (0, 255, 255), thickness=2)\n",
    "        #3rd Row\n",
    "        frame = cv.rectangle(frame, (360, 353), (419, 417), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (552, 353), (610, 417), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (649, 353), (710, 417), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (843, 353), (901, 417), (0, 255, 255), thickness=2)\n",
    "        #4th Row\n",
    "        frame = cv.rectangle(frame, (343, 549), (407, 617), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (547, 549), (607, 617), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (650, 549), (714, 617), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (855, 549), (917, 617), (0, 255, 255), thickness=2)\n",
    "        \n",
    "        # Defining font, scales and thickness.\n",
    "        fontFace = cv.FONT_HERSHEY_DUPLEX \n",
    "        text_scale = 1.2\n",
    "        \n",
    "        #printing of prediction probability and class into the frame\n",
    "        if prediction > 0.5:\n",
    "            text = f'\"PASS\": {np.round(prediction[0][0]*100,2)}%'\n",
    "            frame = cv.putText(frame, text, org=(10,35), fontFace=fontFace, fontScale=text_scale, thickness=2, color=(0, 255, 0), lineType=cv.LINE_AA)\n",
    "        else:\n",
    "            text = f'\"FAIL\": {np.round(prediction[0][0]*100,2)}%'\n",
    "            frame = cv.putText(frame, text, org=(10,35), fontFace=fontFace, fontScale=text_scale, thickness=2, color=(0, 0, 255), lineType=cv.LINE_AA)\n",
    "\n",
    "        #video output\n",
    "        cv.imshow(\"Prediction\", frame)\n",
    "\n",
    "        #out.write(frame) #saving the video output\n",
    "        key=cv.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "                break\n",
    "\n",
    "out.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#release camera if job is done\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production Model Live Video Classification (ROI Dataset/Multiclass)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T16:25:34.009454Z",
     "start_time": "2022-05-11T16:25:32.257252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 250, 200, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 125, 100, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 123, 98, 64)       9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 61, 49, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 191296)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                12243008  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 12,254,915\n",
      "Trainable params: 12,254,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('../model/cnn_model_production/')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "out = cv.VideoWriter('../video/test.avi', fourcc, fps, (int(width), int(height)))\n",
    "\n",
    "while True:\n",
    "        _, frame = cap.read()\n",
    "        \n",
    "        #Convert the captured frame into RGB\n",
    "        imageRGB = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        \n",
    "        #image transformations\n",
    "        im = Image.fromarray(imageRGB)\n",
    "        img_array = np.array(im) / 255\n",
    "\n",
    "        #for ROI models. setting pixels for cropping ROIs\n",
    "        cropped_1strow = np.concatenate((img_array[101:152, 385:435], img_array[101:152, 561:611], img_array[101:152, 655:705], img_array[101:152, 831:881]), axis = 1)\n",
    "        cropped_2ndrow = np.concatenate((img_array[258:323, 375:425], img_array[258:323, 555:605], img_array[258:323, 660:710], img_array[258:323, 838:888]), axis = 1)\n",
    "        cropped_3rdrow = np.concatenate((img_array[353:417, 370:420], img_array[353:417, 550:600], img_array[353:417, 664:714], img_array[353:417, 845:895]), axis = 1)\n",
    "        cropped_4throw = np.concatenate((img_array[549:619, 356:406], img_array[549:619, 550:600], img_array[549:619, 664:714], img_array[549:619, 856:906]), axis = 1)\n",
    "        cropped = np.concatenate((cropped_1strow, cropped_2ndrow, cropped_3rdrow, cropped_4throw), axis = 0)\n",
    "                \n",
    "        #video output of the cropped video\n",
    "        croppedBGR = cv.cvtColor(cropped.astype(np.float32), cv.COLOR_RGB2BGR)\n",
    "        cv.imshow(\"Cropped\", croppedBGR)\n",
    "\n",
    "        #Expand dimensions to match the 4D Tensor shape for prediction\n",
    "        cropped = np.expand_dims(cropped, axis=0)\n",
    "\n",
    "        #prediction\n",
    "        prediction = np.sort(model.predict(cropped))[0][-1] \n",
    "        predict_class = np.argmax(model.predict(cropped))\n",
    "\n",
    "        #Final Picture\n",
    "        #setting rectangles for ROI models\n",
    "        #1st Row\n",
    "        frame = cv.rectangle(frame, (385, 101), (434, 152), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (561, 101), (615, 152), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (650, 101), (705, 152), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (833, 101), (881, 152), (0, 255, 255), thickness=2)\n",
    "        #2nd Row\n",
    "        frame = cv.rectangle(frame, (367, 258), (426, 323), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (554, 258), (610, 323), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (649, 258), (709, 323), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (840, 258), (898, 323), (0, 255, 255), thickness=2)\n",
    "        # #3rd Row\n",
    "        frame = cv.rectangle(frame, (360, 353), (419, 417), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (552, 353), (610, 417), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (649, 353), (710, 417), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (843, 353), (901, 417), (0, 255, 255), thickness=2)\n",
    "        # #4th Row\n",
    "        frame = cv.rectangle(frame, (343, 549), (407, 617), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (547, 549), (607, 617), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (650, 549), (714, 617), (0, 255, 255), thickness=2)\n",
    "        frame = cv.rectangle(frame, (855, 549), (917, 617), (0, 255, 255), thickness=2)\n",
    "        \n",
    "        # Defining font, scales and thickness.\n",
    "        fontFace = cv.FONT_HERSHEY_DUPLEX \n",
    "        text_scale = 1.2\n",
    "        \n",
    "        #printing of prediction probability and class into the frame\n",
    "        if predict_class == 0:\n",
    "            text = f'\"FAIL\": {np.round(prediction*100,2)}%'\n",
    "            frame = cv.putText(frame, text, org=(10,35), fontFace=fontFace, fontScale=text_scale, thickness=2, color=(0, 0, 255), lineType=cv.LINE_AA)\n",
    "        elif predict_class == 1:\n",
    "            text = f'\"PASS\": {np.round(prediction*100,2)}%'\n",
    "            frame = cv.putText(frame, text, org=(10,35), fontFace=fontFace, fontScale=text_scale, thickness=2, color=(0, 255, 0), lineType=cv.LINE_AA)\n",
    "        elif predict_class == 2:\n",
    "            text = f'\"EMPTY\": {np.round(prediction*100,2)}%'\n",
    "            frame = cv.putText(frame, text, org=(10,35), fontFace=fontFace, fontScale=text_scale, thickness=2, color=(255, 255, 255), lineType=cv.LINE_AA)\n",
    "\n",
    "        #video output\n",
    "        cv.imshow(\"Prediction\", frame)\n",
    "        \n",
    "        # out.write(frame) #saving the video output\n",
    "        key=cv.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "                break\n",
    "\n",
    "out.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T16:29:17.048416Z",
     "start_time": "2022-05-11T16:29:16.453945Z"
    }
   },
   "outputs": [],
   "source": [
    "#release camera if job is done\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee8f54c544d987946f3ab7f74ab18a093f1804f651d7338ffa36fa123e5802a2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
